\documentclass[12pt]{article}

\usepackage[T1]{fontenc}
\usepackage[polish]{babel}
\usepackage[utf8]{inputenc}
\usepackage{float}
\usepackage{xcolor}
\usepackage{listings}
\usepackage{enumitem}
\usepackage{indentfirst}
\usepackage{multirow}
\usepackage{pgfplots}
\usepackage{tikz}
\usepackage{url}
\usepackage{titlesec}
\usepackage{hyperref}
\usepackage{algorithm}
\usepackage{algpseudocode}
\pgfplotsset{compat=1.18}
\usepackage{subcaption}

\usepackage[letterpaper,top=2cm,bottom=2cm,left=3cm,right=3cm,marginparwidth=1.75cm]{geometry}
\usepackage{minted}
\usepackage{tabularx}

% Ustawienia dla listingów kodu Python
\lstset{
    language=Python,
    basicstyle=\small\ttfamily,
    keywordstyle=\color{blue},
    commentstyle=\color{green!60!black},
    stringstyle=\color{red},
    showstringspaces=false,
    numbers=left,
    numberstyle=\tiny\color{gray},
    frame=single,
    breaklines=true,
    breakatwhitespace=true,
    tabsize=4
}

% Useful packages
\usepackage{amsmath}
\usepackage{graphicx}
\usepackage{setspace}
\onehalfspacing

\begin{document}

\begin{titlepage}
		\begin{figure}[h]
			\begin{minipage}[l]{.5\textwidth}%
				\includegraphics[width=0.3\textwidth]{pwr_logo}
			\end{minipage}%
			\begin{minipage}[r]{.5\textwidth}%
				\includegraphics[width=1\textwidth]{wit_logo}
			\end{minipage}%
		\end{figure}
		
		\vspace*{3mm}
		
		\begin{center}
			\rule{\textwidth}{0.8pt}\\ 
			\vspace*{6mm}
			{\LARGE \textbf{Badania operacyjne i optymalizacja dyskretna}\\
            
            \vspace*{6mm}
            
            Algorytmy rozwiązywania problemu komiwojażera (TSP)}\\
            \vspace*{3mm}
			\rule{\textwidth}{0.8pt}\\
			
			\vspace{1.5cm}
			{\setstretch{2}
				Politechnika Wrocławska
				
				Wydział Informatyki i Telekomunikacji
				
				Kierunek: Informatyczne Systemy Automatyki
				
				Grupa nr 1
				
				
			}
		\end{center}
		
		\vspace*{2cm}
		
		\begin{flushright}
			{\setstretch{2}
            	Konrad Pempera - $263948$\\
				Dawid Różański - $263524$\\
	
                
				\textbf{Termin zajęć}: Środa godz. $11^{\underline{15}}$ - $13^{\underline{00}}$ 
				
				\textbf{Prowadzący:} Dr inż. Mariusz Makuchowski
				
			}
			
		\end{flushright}
		
		\vfill
		
\end{titlepage}

\tableofcontents
\clearpage

\section{Wstęp}

Problem komiwojażera (Traveling Salesman Problem, TSP) jest jednym z najbardziej znanych i intensywnie badanych zagadnień optymalizacji kombinatorycznej. Polega on na znalezieniu najkrótszej możliwej trasy, która odwiedza każde miasto dokładnie raz i powraca do miasta początkowego. Pomimo prostej definicji, TSP należy do klasy problemów NP-trudnych, co oznacza, że nie znamy algorytmu rozwiązującego go w czasie wielomianowym dla wszystkich przypadków.

TSP ma liczne zastosowania praktyczne w logistyce, planowaniu tras, projektowaniu układów scalonych (PCB), robotyce oraz wielu innych dziedzinach. Ze względu na złożoność obliczeniową problemu, szczególnie dla dużych instancji, opracowano wiele podejść do jego rozwiązywania -- od algorytmów dokładnych dla małych instancji po zaawansowane heurystyki i metaheurystyki dla większych problemów.

\subsection{Cel badań}

Celem niniejszej pracy jest implementacja i porównanie wybranych algorytmów rozwiązywania problemu komiwojażera. Badaniu poddano następujące algorytmy:

\begin{enumerate}
    \item \textbf{Algorytm sekwencyjny} -- najprostsza heurystyka bazowa, odwiedzająca miasta w kolejności ich numeracji
    \item \textbf{Algorytm najbliższego sąsiada (Nearest Neighbor)} -- zachłanna heurystyka konstrukcyjna
    \item \textbf{Algorytm wstawiania najdalszego (Farthest Insertion)} -- konstruktywna heurystyka budująca trasę przez iteracyjne wstawianie miast
    \item \textbf{Algorytm 2-opt} -- metoda lokalnego przeszukiwania poprawiająca istniejące rozwiązanie
    \item \textbf{Przeszukiwanie tabu (Tabu Search)} -- metaheurystyka wykorzystująca pamięć krótkookresową
    \item \textbf{Symulowane wyżarzanie (Simulated Annealing)} -- metaheurystyka inspirowana procesem wyżarzania metali
\end{enumerate}

W pracy przeprowadzono pomiary czasów wykonania oraz jakości uzyskanych rozwiązań dla instancji o różnych rozmiarach. Wyniki pozwalają na ocenę efektywności poszczególnych podejść oraz określenie ich przydatności w praktycznych zastosowaniach.

\subsection{Złożoność obliczeniowa TSP}

Problem komiwojażera jest problemem NP-trudnym, co oznacza że:
\begin{itemize}
    \item Nie znamy algorytmu dokładnego działającego w czasie wielomianowym
    \item Algorytm przeglądu zupełnego ma złożoność $O(n!)$
    \item Dla $n = 20$ miast istnieje już ponad $10^{18}$ możliwych tras
    \item Algorytmy heurystyczne są niezbędne dla dużych instancji problemu
\end{itemize}

W związku z tym, w praktyce stosuje się różne strategie:
\begin{itemize}
    \item Algorytmy dokładne (Branch \& Bound, programowanie dynamiczne) -- dla małych instancji (do około 20 miast)
    \item Heurystyki konstrukcyjne (Nearest Neighbor, Farthest Insertion) -- szybkie, ale nie gwarantujące optymalności
    \item Metody lokalnego przeszukiwania (2-opt, 3-opt) -- poprawa istniejących rozwiązań
    \item Metaheurystyki (Tabu Search, Simulated Annealing, algorytmy ewolucyjne) -- zaawansowane techniki eksploracji przestrzeni rozwiązań
\end{itemize}

\newpage

\section{Opis implementacji algorytmów}

Wszystkie algorytmy zostały zaimplementowane w języku Python 3. Jako reprezentację problemu wykorzystano macierz kosztów, gdzie element $matrix[i][j]$ reprezentuje koszt przejścia z miasta $i$ do miasta $j$. Rozwiązanie problemu to permutacja miast reprezentowana jako lista indeksów tworzących cykl Hamiltona.

\subsection{Algorytm sekwencyjny}

Algorytm sekwencyjny (algorytm 123) jest najprostszą możliwą heurystyką, służącą jako punkt odniesienia dla pozostałych metod. Tworzy trasę odwiedzając miasta w kolejności ich numeracji: $0 \rightarrow 1 \rightarrow 2 \rightarrow \ldots \rightarrow n-1 \rightarrow 0$.

\textbf{Złożoność czasowa:} $O(n)$ -- algorytm wykonuje tylko pojedyncze przejście przez listę miast i oblicza koszt trasy.

\textbf{Zalety:}
\begin{itemize}
    \item Ekstremalnie szybki
    \item Prosty w implementacji
    \item Deterministyczny
\end{itemize}

\textbf{Wady:}
\begin{itemize}
    \item Całkowicie ignoruje strukturę problemu
    \item Zazwyczaj daje bardzo słabe rozwiązania
    \item Użyteczny jedynie jako baseline do porównań
\end{itemize}

\newpage

\subsection{Algorytm najbliższego sąsiada (Nearest Neighbor)}

Algorytm najbliższego sąsiada jest zachłanną heurystyką konstrukcyjną. W każdym kroku wybiera najbliższe nieodwiedzone miasto jako następne w trasie.

\textbf{Pseudokod:}
\begin{algorithmic}[1]
\State $visited \gets \emptyset$
\State $path \gets [start]$
\State $current \gets start$
\State $visited[start] \gets true$
\While{nie odwiedzono wszystkich miast}
    \State $nearest \gets$ najbliższe nieodwiedzone miasto od $current$
    \State $path.append(nearest)$
    \State $visited[nearest] \gets true$
    \State $current \gets nearest$
\EndWhile
\State $path.append(start)$ \Comment{Powrót do początku}
\end{algorithmic}

\textbf{Złożoność czasowa:} $O(n^2)$ -- dla każdego z $n$ miast przeszukujemy pozostałe miasta w poszukiwaniu najbliższego.

\textbf{Zalety:}
\begin{itemize}
    \item Szybki
    \item Prosty w implementacji
    \item Daje sensowne rozwiązania w praktyce
    \item Może być uruchomiony z różnych miast startowych
\end{itemize}

\textbf{Wady:}
\begin{itemize}
    \item Podejście zachłanne nie gwarantuje optymalności
    \item Może dawać słabe wyniki dla niektórych instancji
    \item Decyzje wczesne są nieodwracalne
\end{itemize}

\newpage

\subsection{Algorytm wstawiania najdalszego (Farthest Insertion)}

Algorytm wstawiania najdalszego to heurystyka konstrukcyjna, która iteracyjnie buduje trasę. W każdym kroku:
\begin{enumerate}
    \item Znajduje miasto najdalej oddalone od aktualnej trasy
    \item Wstawia je w miejsce minimalizujące wzrost długości trasy
\end{enumerate}

\textbf{Pseudokod:}
\begin{algorithmic}[1]
\State Znajdź dwa najbardziej oddalone miasta i utwórz z nich cykl początkowy
\While{nie wszystkie miasta w trasie}
    \State $farthest \gets$ miasto o największej minimalnej odległości od trasy
    \State $best\_pos \gets$ pozycja w trasie minimalizująca wzrost kosztu
    \State Wstaw $farthest$ do trasy na pozycji $best\_pos$
\EndWhile
\end{algorithmic}

\textbf{Złożoność czasowa:} $O(n^3)$ -- dla każdego z $n$ miast ($O(n)$) sprawdzamy wszystkie pozostałe miasta ($O(n)$) i wszystkie pozycje w trasie ($O(n)$).

\textbf{Zalety:}
\begin{itemize}
    \item Często daje lepsze wyniki niż Nearest Neighbor
    \item Bardziej globalne podejście niż heurystyki zachłanne
    \item Dobrze radzi sobie z instancjami geometrycznymi
\end{itemize}

\textbf{Wady:}
\begin{itemize}
    \item Wolniejszy niż Nearest Neighbor
    \item Złożoność $O(n^3)$ ogranicza zastosowanie do średnich instancji
    \item Nadal nie gwarantuje optymalności
\end{itemize}

\newpage

\subsection{Algorytm 2-opt}

Algorytm 2-opt jest metodą lokalnego przeszukiwania poprawiającą istniejące rozwiązanie. Iteracyjnie usuwa dwie krawędzie z trasy i ponownie łączy miasta w inny sposób, jeśli prowadzi to do zmniejszenia kosztu.

\textbf{Idea ruchu 2-opt:}
\begin{itemize}
    \item Wybierz dwie krawędzie: $(a, b)$ i $(c, d)$ gdzie $b \neq c$
    \item Usuń te krawędzie i dodaj $(a, c)$ oraz $(b, d)$
    \item Efekt: odwrócenie kolejności miast między $b$ a $c$
\end{itemize}

\textbf{Pseudokod:}
\begin{algorithmic}[1]
\State $path \gets$ rozwiązanie początkowe
\Repeat
    \State $improved \gets false$
    \For{$i = 0$ to $n-2$}
        \For{$j = i+2$ to $n-1$}
            \State Oblicz $\Delta$ -- zmianę kosztu przy zamianie krawędzi $(i, i+1)$ i $(j, j+1)$
            \If{$\Delta < 0$}
                \State Odwróć kolejność miast między $i+1$ a $j$
                \State $improved \gets true$
                \State \textbf{break}
            \EndIf
        \EndFor
    \EndFor
\Until{$\neg improved$}
\end{algorithmic}

\textbf{Złożoność czasowa:} $O(n^2)$ na iterację, liczba iteracji zależy od danych wejściowych. W praktyce często kilka do kilkudziesięciu iteracji.

\textbf{Zalety:}
\begin{itemize}
    \item Efektywnie poprawia istniejące rozwiązania
    \item Stosunkowo szybki
    \item Prosty w implementacji
    \item Często daje znaczącą poprawę jakości rozwiązania
\end{itemize}

\textbf{Wady:}
\begin{itemize}
    \item Wymaga dobrego rozwiązania początkowego
    \item Znajduje tylko lokalne optimum
    \item Może utknąć w słabym lokalnym optimum
\end{itemize}

\subsection{Przeszukiwanie tabu (Tabu Search)}

Tabu Search to zaawansowana metaheurystyka wykorzystująca pamięć krótkookresową (listę tabu) do unikania cykli i eksploracji nowych obszarów przestrzeni rozwiązań.

\textbf{Kluczowe elementy:}
\begin{itemize}
    \item \textbf{Lista tabu} -- przechowuje ostatnio wykonane ruchy, które są tymczasowo zabronione
    \item \textbf{Kryterium aspiracji} -- pozwala na wykonanie ruchu z listy tabu, jeśli prowadzi do najlepszego dotychczas rozwiązania
    \item \textbf{Strategia dywersyfikacji} -- okresowe restarty lub modyfikacje zwiększające eksplorację
\end{itemize}

\textbf{Pseudokod:}
\begin{algorithmic}[1]
\State $current \gets$ rozwiązanie początkowe
\State $best \gets current$
\State $tabu\_list \gets \emptyset$
\For{$iteration = 1$ to $max\_iterations$}
    \State $best\_move \gets null$
    \State $best\_move\_cost \gets \infty$
    \For{każdy możliwy ruch $m$ w sąsiedztwie}
        \State $new\_cost \gets$ koszt po wykonaniu ruchu $m$
        \If{$m \notin tabu\_list$ lub $new\_cost < best$} \Comment{Kryterium aspiracji}
            \If{$new\_cost < best\_move\_cost$}
                \State $best\_move \gets m$
                \State $best\_move\_cost \gets new\_cost$
            \EndIf
        \EndIf
    \EndFor
    \State Wykonaj $best\_move$
    \State Dodaj $best\_move$ do $tabu\_list$
    \If{rozmiar $tabu\_list > tabu\_size$}
        \State Usuń najstarszy element z $tabu\_list$
    \EndIf
    \If{$current < best$}
        \State $best \gets current$
    \EndIf
\EndFor
\end{algorithmic}

\textbf{Złożoność czasowa:} $O(max\_iterations \cdot n^2)$ -- w każdej iteracji sprawdzamy $O(n^2)$ możliwych ruchów 2-opt.

\textbf{Parametry algorytmu:}
\begin{itemize}
    \item $max\_iterations$ -- liczba iteracji (zazwyczaj 1000-10000)
    \item $tabu\_size$ -- rozmiar listy tabu (zazwyczaj 5-20)
\end{itemize}

\textbf{Zalety:}
\begin{itemize}
    \item Unika utknięcia w lokalnych optimach
    \item Systematycznie eksploruje przestrzeń rozwiązań
    \item Często znajduje lepsze rozwiązania niż proste metody lokalne
    \item Elastyczny -- łatwo dostosować do różnych problemów
\end{itemize}

\textbf{Wady:}
\begin{itemize}
    \item Wymaga dostrojenia parametrów
    \item Wolniejszy niż heurystyki konstrukcyjne
    \item Złożoność implementacji
\end{itemize}

\newpage

\subsection{Symulowane wyżarzanie (Simulated Annealing)}

Symulowane wyżarzanie to metaheurystyka inspirowana procesem wyżarzania metali. Algorytm akceptuje gorsze rozwiązania z prawdopodobieństwem zależnym od "temperatury", co pozwala na ucieczkę z lokalnych optimów.

\textbf{Kluczowe elementy:}
\begin{itemize}
    \item \textbf{Temperatura} $T$ -- parametr kontrolujący prawdopodobieństwo akceptacji gorszych rozwiązań
    \item \textbf{Schemat chłodzenia} -- funkcja określająca jak temperatura maleje w czasie (np. $T_{new} = \alpha \cdot T$, gdzie $\alpha \approx 0.995$)
    \item \textbf{Prawdopodobieństwo akceptacji} -- dla gorszego rozwiązania z $\Delta > 0$: $P = e^{-\Delta/T}$
\end{itemize}

\textbf{Pseudokod:}
\begin{algorithmic}[1]
\State $current \gets$ rozwiązanie początkowe
\State $best \gets current$
\State $T \gets T_{initial}$ \Comment{Wysoka temperatura początkowa}
\While{$T > T_{min}$}
    \State $neighbor \gets$ losowy sąsiad $current$ (np. ruch 2-opt)
    \State $\Delta \gets cost(neighbor) - cost(current)$
    \If{$\Delta < 0$} \Comment{Lepsze rozwiązanie - zawsze akceptuj}
        \State $current \gets neighbor$
    \Else \Comment{Gorsze rozwiązanie - akceptuj z prawdopodobieństwem}
        \State $P \gets e^{-\Delta / T}$
        \If{$random() < P$}
            \State $current \gets neighbor$
        \EndIf
    \EndIf
    \If{$cost(current) < cost(best)$}
        \State $best \gets current$
    \EndIf
    \State $T \gets \alpha \cdot T$ \Comment{Chłodzenie}
\EndWhile
\end{algorithmic}

\textbf{Złożoność czasowa:} $O(liczba\_iteracji \cdot n^2)$ -- w każdej iteracji generujemy i oceniamy nowego sąsiada.
\newpage
\textbf{Parametry algorytmu:}
\begin{itemize}
    \item $T_{initial}$ -- temperatura początkowa (zazwyczaj zależna od średniego kosztu krawędzi)
    \item $\alpha$ -- współczynnik chłodzenia (zazwyczaj 0.99-0.999)
    \item $T_{min}$ -- temperatura minimalna (kryterium stopu)
\end{itemize}

\textbf{Interpretacja fizyczna:}
\begin{itemize}
    \item Wysokie $T$ -- cząsteczki mają dużą energię, łatwo zmieniają położenie (eksploracja)
    \item Niskie $T$ -- cząsteczki stabilizują się w minimum energii (eksploatacja)
    \item Wolne chłodzenie -- zwiększa szansę znalezienia optimum globalnego
\end{itemize}

\textbf{Zalety:}
\begin{itemize}
    \item Unika utknięcia w lokalnych optimach
    \item Teoretycznie gwarantuje znalezienie optimum globalnego przy nieskończenie wolnym chłodzeniu
    \item Prosta koncepcja i implementacja
    \item Mało parametrów do strojenia
\end{itemize}

\textbf{Wady:}
\begin{itemize}
    \item Wymaga doboru odpowiednich parametrów
    \item Może być wolny przy zbyt konserwatywnym chłodzeniu
    \item Brak gwarancji jakości dla skończonej liczby iteracji
\end{itemize}

\newpage

\section{Wyniki eksperymentów}

Eksperymenty przeprowadzono na losowo generowanych instancjach problemu TSP. Dla każdego rozmiaru problemu wykonano po 3-5 powtórzeń z różnymi seedami generatora liczb pseudolosowych. Przedstawione wyniki to wartości średnie wraz z odchyleniem standardowym.

\subsection{Środowisko testowe}

\begin{itemize}
    \item \textbf{Język:} Python 3.12
    \item \textbf{System operacyjny:} Windows 10
    \item \textbf{Generator instancji:} Pseudolosowy generator z seedem, tworzy asymetryczne macierze kosztów z wartościami od 1 do 99
    \item \textbf{Rozmiary testowane:} $n \in \{5, 10, 50, 75, 100, 150, 200, 300, 400, 500\}$
    \item \textbf{Liczba powtórzeń:} 10 dla każdego rozmiaru (wyniki uśrednione)
    \item \textbf{Timeout:} 100 sekund na pojedynczy test -- po przekroczeniu algorytm jest przerywany i oznaczany jako ``--''
    \item \textbf{Seed generatora:} Dla każdego powtórzenia używany jest inny seed (bazowy seed + offset zależny od rozmiaru i numeru powtórzenia), co zapewnia różnorodność instancji przy zachowaniu powtarzalności eksperymentów
\end{itemize}

\textbf{Uwaga o asymetrii:} Generowane instancje są asymetryczne ($matrix[i][j] \neq matrix[j][i]$), co jest bardziej realistyczne dla wielu praktycznych zastosowań (np. ruch jednokierunkowy, różne koszty w zależności od kierunku). Asymetria może wpływać na skuteczność algorytmów opartych na 2-opt, które oryginalnie były projektowane dla symetrycznego TSP.

\subsection{Porównanie czasów wykonania}

Poniżej przedstawiono porównanie czasów wykonania poszczególnych algorytmów dla różnych rozmiarów instancji problemu. Tabela~\ref{tab:time_comparison} zawiera szczegółowe wartości, natomiast Rysunek~\ref{fig:time_plot} wizualizuje skalowalność algorytmów.

\begin{table}[H]
\centering
\caption{Porównanie czasów wykonania algorytmów [s]}
\label{tab:time_comparison}
\begin{tabular}{|c|c|c|c|c|c|c|}
\hline
\textbf{n} & \textbf{Sekw.} & \textbf{NN} & \textbf{FI} & \textbf{2-opt} & \textbf{TS} & \textbf{SA} \\
\hline
5 & 0.000 & 0.000 & 0.000 & 0.000 & 0.000 & 0.015 \\
10 & 0.000 & 0.000 & 0.000 & 0.000 & 0.011 & 0.093 \\
50 & 0.000 & 0.000 & 0.011 & 0.011 & 1.133 & 4.855 \\
75 & 0.000 & 0.000 & 0.011 & 0.019 & 1.042 & 5.400 \\
100 & 0.000 & 0.000 & 0.020 & 0.140 & 4.163 & 6.518 \\
150 & 0.000 & 0.002 & 0.066 & 0.160 & 5.081 & -- \\
200 & 0.000 & 0.001 & 0.160 & 0.746 & 8.308 & -- \\
300 & 0.000 & 0.000 & 0.526 & 3.069 & -- & -- \\
400 & 0.000 & 0.008 & 1.303 & 3.732 & -- & -- \\
500 & 0.000 & 0.003 & 2.597 & 7.417 & -- & -- \\
\hline
\end{tabular}
\end{table}

\begin{figure}[H]
\centering
\begin{tikzpicture}
\begin{semilogyaxis}[
    width=14cm,
    height=9cm,
    xlabel={Rozmiar problemu $n$},
    ylabel={Czas wykonania [s]},
    legend pos=south east,
    grid=major,
    legend style={font=\footnotesize},
    xmin=0, xmax=520,
    ymin=0.001, ymax=20,
    xtick={5,10,50,75,100,150,200,300,400,500},
]
\addplot[color=green!60!black,mark=triangle*,thick] coordinates {
    (5,0.001) (10,0.001) (50,0.011) (75,0.011) (100,0.020) (150,0.066) (200,0.160) (300,0.526) (400,1.303) (500,2.597)
};
\addplot[color=orange,mark=diamond*,thick] coordinates {
    (5,0.001) (10,0.001) (50,0.011) (75,0.019) (100,0.140) (150,0.160) (200,0.746) (300,3.069) (400,3.732) (500,7.417)
};
\addplot[color=purple,mark=pentagon*,thick] coordinates {
    (5,0.001) (10,0.011) (50,1.133) (75,1.042) (100,4.163) (150,5.081) (200,8.308)
};
\addplot[color=brown,mark=*,thick,dashed] coordinates {
    (5,0.015) (10,0.093) (50,4.855) (75,5.400) (100,6.518)
};
\legend{Farthest Insertion, 2-opt, Tabu Search, Simulated Annealing}
\end{semilogyaxis}
\end{tikzpicture}
\caption{Czasy wykonania algorytmów w zależności od rozmiaru problemu (skala logarytmiczna na osi Y). Algorytmy Sekwencyjny i Nearest Neighbor mają czasy bliskie 0 i nie są widoczne na wykresie. TS i SA przekraczają timeout dla większych $n$.}
\label{fig:time_plot}
\end{figure}

\textbf{Obserwacje:}
\begin{itemize}
    \item Algorytm sekwencyjny i Nearest Neighbor są najszybsze -- czasy bliskie 0 dla wszystkich testowanych rozmiarów
    \item Farthest Insertion ma złożoność $O(n^3)$ -- czas rośnie od 0.01s dla $n=50$ do 2.6s dla $n=500$
    \item 2-opt ma podobną charakterystykę do FI -- czas rośnie do 7.4s dla $n=500$
    \item Tabu Search jest znacząco wolniejszy -- przekracza timeout (100s) dla $n \geq 300$
    \item Simulated Annealing jest najwolniejszy -- przekracza timeout już dla $n \geq 150$
    \item Metaheurystyki (TS i SA) wymagają znacznie więcej czasu, ale dla mniejszych instancji dają lepsze wyniki
\end{itemize}

\subsection{Porównanie jakości rozwiązań}

Poniżej przedstawiono porównanie jakości rozwiązań uzyskanych przez poszczególne algorytmy. Tabela~\ref{tab:quality_comparison} zawiera szczegółowe wartości kosztów tras wraz z procentową różnicą względem najlepszego rozwiązania, natomiast Rysunek~\ref{fig:quality_plot} wizualizuje zależność jakości od rozmiaru problemu.

\begin{table}[H]
\centering
\caption{Porównanie jakości rozwiązań -- koszt trasy}
\label{tab:quality_comparison}
\begin{tabular}{|c|c|c|c|c|c|c|}
\hline
\textbf{n} & \textbf{Sekw.} & \textbf{NN} & \textbf{FI} & \textbf{2-opt} & \textbf{TS} & \textbf{SA} \\
\hline
5 & 241 & 241 & 241 & 241 & 191 & 191 \\
 & (+26\%) & (+26\%) & (+26\%) & (+26\%) & (0\%) & (0\%) \\
\hline
10 & 612 & 286 & 177 & 286 & 184 & 232 \\
 & (+233\%) & (+55\%) & (-4\%) & (+55\%) & (0\%) & (+26\%) \\
\hline
50 & 2770 & 380 & 458 & 380 & 325 & 380 \\
 & (+752\%) & (+17\%) & (+41\%) & (+17\%) & (0\%) & (+17\%) \\
\hline
75 & 4086 & 421 & 612 & 421 & 421 & 421 \\
 & (+871\%) & (0\%) & (+45\%) & (0\%) & (0\%) & (0\%) \\
\hline
100 & 4860 & 609 & 753 & 548 & 489 & 489 \\
 & (+894\%) & (+25\%) & (+54\%) & (+12\%) & (0\%) & (0\%) \\
\hline
150 & 7635 & 618 & 956 & 618 & 540 & -- \\
 & (+1314\%) & (+14\%) & (+77\%) & (+14\%) & (0\%) & -- \\
\hline
200 & 9134 & 666 & 1012 & 663 & 577 & -- \\
 & (+1483\%) & (+15\%) & (+75\%) & (+15\%) & (0\%) & -- \\
\hline
\end{tabular}
\end{table}

\begin{figure}[H]
\centering
\begin{tikzpicture}
\begin{semilogyaxis}[
    width=14cm,
    height=9cm,
    xlabel={Rozmiar problemu $n$},
    ylabel={Koszt trasy (skala log)},
    legend pos=north west,
    grid=major,
    legend style={font=\footnotesize},
    xmin=0, xmax=520,
    ymin=100, ymax=30000,
    xtick={5,10,50,75,100,150,200,300,400,500},
]
\addplot[color=red,mark=*,thick] coordinates {
    (5,241) (10,612) (50,2770) (75,4086) (100,4860) (150,7635) (200,9134) (300,14059) (400,20001) (500,25493)
};
\addplot[color=blue,mark=square*,thick] coordinates {
    (5,241) (10,286) (50,380) (75,421) (100,609) (150,618) (200,666) (300,735) (400,788) (500,1077)
};
\addplot[color=green!60!black,mark=triangle*,thick] coordinates {
    (5,241) (10,177) (50,458) (75,612) (100,753) (150,956) (200,1012) (300,1322) (400,1475) (500,1764)
};
\addplot[color=orange,mark=diamond*,thick] coordinates {
    (5,241) (10,286) (50,380) (75,421) (100,548) (150,618) (200,663) (300,706) (400,788) (500,1077)
};
\addplot[color=purple,mark=pentagon*,thick] coordinates {
    (5,191) (10,184) (50,325) (75,421) (100,489) (150,540) (200,577)
};
\addplot[color=brown,mark=*,thick,dashed] coordinates {
    (5,191) (10,232) (50,380) (75,421) (100,489)
};
\legend{Sekwencyjny, Nearest Neighbor, Farthest Insertion, 2-opt, Tabu Search, Simulated Annealing}
\end{semilogyaxis}
\end{tikzpicture}
\caption{Jakość rozwiązań (koszt trasy) w zależności od rozmiaru problemu (skala logarytmiczna na osi Y). Wartości w nawiasach w tabeli pokazują procentową różnicę względem najlepszego rozwiązania dla danego rozmiaru. TS i SA nie mają wyników dla większych $n$ z powodu przekroczenia timeout.}
\label{fig:quality_plot}
\end{figure}

\textbf{Obserwacje:}
\begin{itemize}
    \item Algorytm sekwencyjny daje katastrofalnie słabe rozwiązania -- od 26\% do ponad 1400\% gorsze od najlepszych
    \item Nearest Neighbor daje dobre rozwiązania (0-55\% od najlepszych) przy minimalnym czasie wykonania
    \item Farthest Insertion zaskakująco daje gorsze wyniki niż NN dla większych $n$ -- do 77\% gorsze od najlepszych
    \item 2-opt poprawia rozwiązanie NN tylko nieznacznie (12-17\% od najlepszych dla $n \geq 100$)
    \item Tabu Search daje najlepsze wyniki tam gdzie działa (do $n=200$)
    \item Simulated Annealing daje wyniki porównywalne z TS dla małych $n$, ale szybko przekracza timeout
    \item Dla dużych instancji ($n \geq 300$) jedynie algorytmy heurystyczne (NN, FI, 2-opt) są praktyczne
\end{itemize}

\subsection{Analiza kompromisu czas-jakość}

Kluczową kwestią w praktycznych zastosowaniach jest wybór odpowiedniego algorytmu w zależności od wymagań dotyczących czasu wykonania i jakości rozwiązania.

\textbf{Scenariusze zastosowań:}

\begin{enumerate}
    \item \textbf{Wymagana bardzo krótka odpowiedź} (ms): Nearest Neighbor
    \begin{itemize}
        \item Czas: poniżej 10ms nawet dla $n=500$
        \item Jakość: 15-25\% gorsza od najlepszych rozwiązań dla większych $n$
        \item Zastosowanie: aplikacje czasu rzeczywistego, wstępne przybliżenia
    \end{itemize}
    
    \item \textbf{Balans czas-jakość} (setki ms do sekund): 2-opt z początkowym NN
    \begin{itemize}
        \item Czas: 0.14s dla $n=100$, do 7.4s dla $n=500$
        \item Jakość: 12-17\% od najlepszych rozwiązań dla średnich $n$
        \item Zastosowanie: typowe problemy optymalizacji tras dla $n \leq 500$
    \end{itemize}
    
    \item \textbf{Priorytet jakości} (sekundy): Tabu Search
    \begin{itemize}
        \item Czas: 4-8 sekund dla $n=100-200$
        \item Jakość: najlepsza spośród testowanych algorytmów
        \item Zastosowanie: planowanie offline dla mniejszych instancji ($n \leq 200$)
    \end{itemize}
    
    \item \textbf{Duże instancje} ($n > 200$): tylko heurystyki
    \begin{itemize}
        \item Metaheurystyki przekraczają praktyczne limity czasowe
        \item Kombinacja NN + 2-opt jest najlepszym wyborem
        \item Dla $n=500$: koszt 1077 przy czasie 7.4s
    \end{itemize}
\end{enumerate}

\subsection{Wpływ parametrów na metaheurystyki}

\subsubsection{Tabu Search}

Implementacja wykorzystuje następujące parametry:

\begin{itemize}
    \item \textbf{Rozmiar listy tabu:} Adaptacyjny, zależny od $n$ (7-20)
    \item \textbf{Liczba iteracji:} Adaptacyjna -- od 1500 dla małych $n$ do 500 dla dużych
    \item \textbf{Sąsiedztwo:} Ruchy 2-opt z próbkowaniem dla większych instancji
    \item \textbf{Kryterium aspiracji:} Akceptacja ruchu z listy tabu jeśli daje globalne najlepsze rozwiązanie
\end{itemize}

Głównym ograniczeniem jest czas wykonania -- dla $n > 200$ algorytm przekracza praktyczne limity czasowe.

\subsubsection{Simulated Annealing}

Implementacja wykorzystuje następujące parametry:

\begin{itemize}
    \item \textbf{Temperatura początkowa:} $T_0 = avg\_cost \cdot n \cdot 50$ (adaptacyjna)
    \item \textbf{Współczynnik chłodzenia:} Obliczany adaptacyjnie na podstawie liczby iteracji
    \item \textbf{Sąsiedztwo:} Próbkowanie najlepszego z wielu losowych ruchów 2-opt
    \item \textbf{Lokalna optymalizacja:} 2-opt na końcu, jeśli SA znalazło poprawę
\end{itemize}

SA okazał się najbardziej czasochłonny spośród testowanych algorytmów, przekraczając timeout już dla $n \geq 150$. Strategia próbkowania wielu sąsiadów poprawia jakość kosztem czasu.

\section{Wnioski}

\subsection{Wnioski ogólne}

\begin{enumerate}
    \item \textbf{Kompromis czas-jakość:} Nie istnieje jeden najlepszy algorytm -- wybór zależy od wymagań aplikacji i rozmiaru problemu:
    \begin{itemize}
        \item Dla aplikacji czasu rzeczywistego i dużych $n$: Nearest Neighbor
        \item Dla typowych zastosowań ($n \leq 500$): 2-opt z początkiem z NN
        \item Gdy jakość jest priorytetem i $n \leq 200$: Tabu Search
        \item Simulated Annealing jest praktyczny tylko dla $n < 150$
    \end{itemize}
    
    \item \textbf{Skuteczność metaheurystyk:} Tabu Search daje najlepsze wyniki spośród testowanych algorytmów, ale jest ograniczony do mniejszych instancji ($n \leq 200$). Simulated Annealing przekracza timeout jeszcze szybciej.
    
    \item \textbf{Zaskakująca wydajność heurystyk:} Nearest Neighbor okazał się lepszy niż Farthest Insertion dla większych instancji, mimo że FI ma wyższą złożoność obliczeniową. 2-opt daje tylko nieznaczną poprawę względem NN.
    
    \item \textbf{Skalowalność:} Dla instancji $n > 200$ jedynie algorytmy heurystyczne (Sekwencyjny, NN, FI, 2-opt) są praktyczne. Metaheurystyki przekraczają timeout 100s.
    
    \item \textbf{Asymetryczny TSP:} Testowane instancje były asymetryczne (macierz kosztów niesymetryczna), co może wpływać na skuteczność niektórych algorytmów, szczególnie tych opartych na 2-opt.
\end{enumerate}


\section{Podsumowanie}

W ramach przeprowadzonych badań zaimplementowano i porównano sześć algorytmów rozwiązywania problemu komiwojażera: algorytm sekwencyjny, Nearest Neighbor, Farthest Insertion, 2-opt, Tabu Search oraz Simulated Annealing. Eksperymenty numeryczne na instancjach o rozmiarach od 5 do 500 miast pozwoliły na dokładną ocenę wydajności i jakości rozwiązań dla każdej z metod.

Wyniki potwierdzają fundamentalny kompromis między czasem wykonania a jakością rozwiązań. Algorytm sekwencyjny i Nearest Neighbor są najszybsze (czas bliski 0), przy czym NN daje znacząco lepsze rozwiązania. Farthest Insertion, mimo wyższej złożoności obliczeniowej, okazał się gorszy od NN dla większych instancji. Algorytm 2-opt oferuje nieznaczną poprawę względem NN przy akceptowalnym czasie (do 7.4s dla $n=500$).

Metaheurystyki (Tabu Search i Simulated Annealing) dają najlepsze wyniki, ale są ograniczone do mniejszych instancji -- TS przekracza timeout dla $n \geq 300$, a SA już dla $n \geq 150$. Tabu Search okazał się najbardziej skuteczny spośród testowanych metaheurystyk.

Praktycznym wnioskiem jest zalecenie:
\begin{itemize}
    \item Dla małych instancji ($n \leq 100$): Tabu Search dla najlepszej jakości
    \item Dla średnich instancji ($100 < n \leq 200$): Tabu Search lub 2-opt z NN
    \item Dla dużych instancji ($n > 200$): kombinacja Nearest Neighbor + 2-opt
\end{itemize}

Przeprowadzone badania stanowią solidną podstawę do wyboru odpowiedniego algorytmu w praktycznych zastosowaniach optymalizacji tras.
\section{Bibliografia}

\begin{enumerate}
    \item Applegate, D. L., Bixby, R. E., Chvátal, V., \& Cook, W. J. (2006). \textit{The traveling salesman problem: a computational study}. Princeton university press.
    
    \item Laporte, G. (1992). The traveling salesman problem: An overview of exact and approximate algorithms. \textit{European Journal of Operational Research}, 59(2), 231-247.
    
    \item Glover, F., \& Laguna, M. (1998). \textit{Tabu search}. Springer.
    
    \item Kirkpatrick, S., Gelatt, C. D., \& Vecchi, M. P. (1983). Optimization by simulated annealing. \textit{Science}, 220(4598), 671-680.
    
    \item Lawler, E. L., Lenstra, J. K., Rinnooy Kan, A. H. G., \& Shmoys, D. B. (1985). \textit{The traveling salesman problem: A guided tour of combinatorial optimization}. Wiley.
    
    \item Rosenkrantz, D. J., Stearns, R. E., \& Lewis, P. M. (1977). An analysis of several heuristics for the traveling salesman problem. \textit{SIAM journal on computing}, 6(3), 563-581.
    
    \item Croes, G. A. (1958). A method for solving traveling-salesman problems. \textit{Operations research}, 6(6), 791-812.
    
    \item Gendreau, M., \& Potvin, J. Y. (Eds.). (2010). \textit{Handbook of metaheuristics} (Vol. 2). New York: Springer.
\end{enumerate}

\end{document}